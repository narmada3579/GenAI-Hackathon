# -*- coding: utf-8 -*-
"""GenAI Hackathon.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UdB0cDlbbnsw1U_gydOxtpx3dhvdsQa7
"""

!pip install kagglehub
!pip install surprise
!pip install pandas

import kagglehub

# Download latest version of the dataset
path = kagglehub.dataset_download("arashnic/book-recommendation-dataset")

print("Path to dataset files:", path)

from google.colab import files
files.upload()  # This will prompt you to upload the 'kaggle.json' file

# Install Kaggle API and upload credentials (if using Google Colab)
!pip install kaggle

# Upload your Kaggle API key (kaggle.json) using Colab's file upload prompt
from google.colab import files
files.upload()  # This will prompt you to upload your 'kaggle.json'

# Set Kaggle API credentials
import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content"

# Download the dataset from Kaggle (Book Recommendation Dataset example)
!kaggle datasets download -d arashnic/book-recommendation-dataset

# Unzip the downloaded file
!unzip book-recommendation-dataset.zip

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from surprise import SVD, Dataset, Reader
from surprise.model_selection import train_test_split, cross_validate

# Load the data (assuming 'ratings.csv' and 'books.csv' are the required files)
ratings = pd.read_csv('ratings.csv')
books = pd.read_csv('books.csv')

# Display basic dataset information
print("Ratings Dataset Info:")
print(ratings.info())
print("Books Dataset Info:")
print(books.info())

# Check for missing values and handle them
ratings = ratings.dropna(subset=['userId', 'bookId', 'rating'])
books = books.dropna(subset=['bookId', 'title'])

# Ensure data types are correct
ratings['rating'] = ratings['rating'].astype(float)

# Display unique counts of users and books
print(f"Unique Users: {ratings['userId'].nunique()}")
print(f"Unique Books: {ratings['bookId'].nunique()}")

# Content-Based Filtering using TF-IDF
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(books['title'])

# Calculate cosine similarity between books based on their titles
book_similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)

# Function to get similar books based on content similarity (title-based)
def get_similar_books(book_id, n=5):
    idx = books[books['bookId'] == book_id].index[0]
    similarity_scores = list(enumerate(book_similarity[idx]))
    sorted_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)
    top_n = [books.iloc[i[0]]['bookId'] for i in sorted_scores[1:n+1]]
    return top_n

# Example: Get similar books for a given book
book_id = books['bookId'].iloc[0]
print(f"Top similar books for {book_id}: {get_similar_books(book_id)}")

# Collaborative Filtering using Surprise Library
reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(ratings[['userId', 'bookId', 'rating']], reader)

# Split the dataset into training and testing sets
trainset, testset = train_test_split(data, test_size=0.25)

# Build and train the collaborative filtering model
model = SVD()
model.fit(trainset)

# Cross-validation to evaluate the model
cv_results = cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)

# Display evaluation metrics
print(f"Average RMSE: {np.mean(cv_results['test_rmse']):.4f}")
print(f"Average MAE: {np.mean(cv_results['test_mae']):.4f}")

# Function to recommend books using both collaborative filtering and content-based filtering
def recommend_books(user_id, ratings, books, model, top_n=5):
    # Collaborative Filtering: Predict ratings for books the user hasn't rated
    user_rated = ratings[ratings['userId'] == user_id]['bookId'].tolist()
    all_books = books['bookId'].unique()
    unrated_books = [b for b in all_books if b not in user_rated]

    predicted_ratings = [(book, model.predict(user_id, book).est) for book in unrated_books]
    top_collaborative = sorted(predicted_ratings, key=lambda x: x[1], reverse=True)[:top_n]

    # Content-Based Filtering: Get similar books to the top collaborative recommendations
    hybrid_recommendations = []
    for book, _ in top_collaborative:
        hybrid_recommendations.extend(get_similar_books(book, n=3))

    # Remove duplicates and limit results
    final_recommendations = list(set(hybrid_recommendations))[:top_n]
    return final_recommendations

# Example: Recommend books for a user
user_id = ratings['userId'].iloc[0]
recommendations = recommend_books(user_id, ratings, books, model, top_n=5)
print(f"Recommendations for User {user_id}: {recommendations}")